{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_adj_matrix_path = os.path.join('distances23.csv')\n",
    "W = pd.read_csv(weighted_adj_matrix_path).drop('station_id', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_pickle(r'C:\\Users\\srush\\bike share model\\cleaned&merged_data\\All_Rides.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering JC Stations for analysis\n",
    "jc_stations = ['JC102', 'JC096', 'JC0003', 'JC099', 'JC023', 'JC081', 'JC075', 'JC078', 'JC063', 'JC080', 'JC072', 'JC013', 'JC002', 'JC076', 'JC032', 'JC027', 'JC009', 'JC105', 'JC053', 'JC093', 'JC020', 'JC094', 'JC056', 'JC103', 'JC038', 'JC006', 'JC104', 'JC008', 'JC0084', 'JC065', 'JC024', 'JC059', 'JC0011', 'JC0035', 'JC005', 'JC082', 'JC074', 'JC055', 'JC022', 'JC106', 'JC014', 'JC098', 'JC066', 'JC052', 'JC051', 'JC077', 'JC0095', 'JC019', 'JC018', 'JC0034', 'JC057']\n",
    "\n",
    "df = all_df[(all_df['start_station_id'].isin(jc_stations)) & (all_df['end_station_id'].isin(jc_stations))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srush\\AppData\\Local\\Temp\\ipykernel_14520\\1621484384.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['started_at'] = pd.to_datetime(df['started_at'])\n",
      "C:\\Users\\srush\\AppData\\Local\\Temp\\ipykernel_14520\\1621484384.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ended_at'] = pd.to_datetime(df['ended_at'])\n"
     ]
    }
   ],
   "source": [
    "#converting to date and time type\n",
    "df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define start and end dates\n",
    "start_date = '2023-03-01 00:00:00'\n",
    "end_date = '2023-05-31 23:55:00'\n",
    "\n",
    "# Create a mask for the 'started_at' column\n",
    "start_date_mask = df['started_at'].between(start_date, end_date)\n",
    "\n",
    "# Apply the mask to the DataFrame\n",
    "df = df[start_date_mask]\n",
    "\n",
    "# Create a mask for the 'ended_at' column\n",
    "end_date_mask = df['ended_at'].between(start_date, end_date)\n",
    "\n",
    "# Apply the mask to the DataFrame\n",
    "df = df[end_date_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum start datetime: 2023-05-31 23:39:40\n",
      "Minimum start datetime: 2023-03-01 00:25:35\n",
      "Maximum end datetime: 2023-05-31 23:44:45\n",
      "Minimum end datetime: 2023-03-01 00:31:59\n"
     ]
    }
   ],
   "source": [
    "max_sdatetime = df['started_at'].max()\n",
    "min_sdatetime = df['started_at'].min()\n",
    "\n",
    "print(\"Maximum start datetime:\", max_sdatetime)\n",
    "print(\"Minimum start datetime:\", min_sdatetime)\n",
    "\n",
    "max_edatetime = df['ended_at'].max()\n",
    "min_edatetime = df['ended_at'].min()\n",
    "\n",
    "print(\"Maximum end datetime:\", max_edatetime)\n",
    "print(\"Minimum end datetime:\", min_edatetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_start_time = max(min_sdatetime, min_edatetime)\n",
    "common_end_time = min(max_sdatetime, max_edatetime)\n",
    "\n",
    "df = df[(df['started_at'] >= common_start_time) & (df['started_at'] <= common_end_time)]\n",
    "df = df[(df['ended_at'] >= common_start_time) & (df['ended_at'] <= common_end_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum start datetime: 2023-05-31 23:19:50\n",
      "Minimum start datetime: 2023-03-01 00:43:53\n",
      "Maximum end datetime: 2023-05-31 23:29:28\n",
      "Minimum end datetime: 2023-03-01 00:48:33\n"
     ]
    }
   ],
   "source": [
    "max_sdatetime = df['started_at'].max()\n",
    "min_sdatetime = df['started_at'].min()\n",
    "\n",
    "print(\"Maximum start datetime:\", max_sdatetime)\n",
    "print(\"Minimum start datetime:\", min_sdatetime)\n",
    "\n",
    "max_edatetime = df['ended_at'].max()\n",
    "min_edatetime = df['ended_at'].min()\n",
    "\n",
    "print(\"Maximum end datetime:\", max_edatetime)\n",
    "print(\"Minimum end datetime:\", min_edatetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All unique stations in Jersey City\n",
    "unique_stations = set(df['start_station_name']).union(set(df['end_station_name']))\n",
    "number_of_unique_stations = len(unique_stations)\n",
    "number_of_unique_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of station IDs to matrix indices\n",
    "station_index = {station: idx for idx, station in enumerate(unique_stations)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.zeros((number_of_unique_stations, number_of_unique_stations), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    start_idx = station_index[row['start_station_name']]\n",
    "    end_idx = station_index[row['end_station_name']]\n",
    "    adjacency_matrix[start_idx, end_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('adjacency_matrix.npy', adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rides for each start station\n",
    "start_station_counts = df.groupby('start_station_name').size().sort_values(ascending=False)\n",
    "\n",
    "# Count the number of rides for each end station\n",
    "end_station_counts = df.groupby('end_station_name').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58098, 12)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create in-data frame : stations and their incoming rides\n",
    "in_df = df.drop(['started_at', 'start_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng','member_casual','start_station_name','end_station_name'], axis=1)\n",
    "in_df['time'] = df['ended_at']\n",
    "#in_df = in_df[(in_df['time'] >= '2017-01-01 00:21:00') & (in_df['time'] <= '2023-09-30 23:59:59')]\n",
    "in_df['station_id'] = df['end_station_id']\n",
    "in_df = in_df.drop(['ended_at', 'end_station_id'], axis=1)\n",
    "\n",
    "# out-dataframe : stations with the rides leaving the station\n",
    "out_df = df.drop(['ended_at', 'end_station_id','start_lat', 'start_lng', 'end_lat', 'end_lng','member_casual','start_station_name','end_station_name'], axis=1)\n",
    "out_df['time'] = df['started_at']\n",
    "#out_df = out_df[(out_df['time'] >= '2017-01-01 00:21:00') & (out_df['time'] <= '2023-09-30 23:59:59')]\n",
    "out_df['station_id'] = df['start_station_id']\n",
    "out_df = out_df.drop(['started_at', 'start_station_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>time</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1875342</th>\n",
       "      <td>2ED9BC6D822C18D9</td>\n",
       "      <td>2023-05-23 18:25:32</td>\n",
       "      <td>JC008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875344</th>\n",
       "      <td>53D865CBD9BFC5F4</td>\n",
       "      <td>2023-05-07 08:06:04</td>\n",
       "      <td>JC008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875345</th>\n",
       "      <td>ABAFB5950E7C79B7</td>\n",
       "      <td>2023-05-06 02:44:09</td>\n",
       "      <td>JC006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875347</th>\n",
       "      <td>E266F73A92C04C92</td>\n",
       "      <td>2023-05-31 15:54:00</td>\n",
       "      <td>JC008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875352</th>\n",
       "      <td>CABAC21C0F0140A5</td>\n",
       "      <td>2023-05-16 12:04:04</td>\n",
       "      <td>JC008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ride_id                time station_id\n",
       "1875342  2ED9BC6D822C18D9 2023-05-23 18:25:32      JC008\n",
       "1875344  53D865CBD9BFC5F4 2023-05-07 08:06:04      JC008\n",
       "1875345  ABAFB5950E7C79B7 2023-05-06 02:44:09      JC006\n",
       "1875347  E266F73A92C04C92 2023-05-31 15:54:00      JC008\n",
       "1875352  CABAC21C0F0140A5 2023-05-16 12:04:04      JC008"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58098, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>time</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1875342</th>\n",
       "      <td>2ED9BC6D822C18D9</td>\n",
       "      <td>2023-05-23 18:19:10</td>\n",
       "      <td>JC014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875344</th>\n",
       "      <td>53D865CBD9BFC5F4</td>\n",
       "      <td>2023-05-07 07:56:04</td>\n",
       "      <td>JC014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875345</th>\n",
       "      <td>ABAFB5950E7C79B7</td>\n",
       "      <td>2023-05-06 02:42:43</td>\n",
       "      <td>JC014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875347</th>\n",
       "      <td>E266F73A92C04C92</td>\n",
       "      <td>2023-05-31 15:39:26</td>\n",
       "      <td>JC014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875352</th>\n",
       "      <td>CABAC21C0F0140A5</td>\n",
       "      <td>2023-05-16 11:56:11</td>\n",
       "      <td>JC014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ride_id                time station_id\n",
       "1875342  2ED9BC6D822C18D9 2023-05-23 18:19:10      JC014\n",
       "1875344  53D865CBD9BFC5F4 2023-05-07 07:56:04      JC014\n",
       "1875345  ABAFB5950E7C79B7 2023-05-06 02:42:43      JC014\n",
       "1875347  E266F73A92C04C92 2023-05-31 15:39:26      JC014\n",
       "1875352  CABAC21C0F0140A5 2023-05-16 11:56:11      JC014"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58098, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16992"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of 5-minute intervals throughout the data\n",
    "timestep = 5\n",
    "date_range = pd.date_range(start='2023-03-01 00:00:00', end='2023-04-28 23:55:00', freq=f'{timestep}T')\n",
    "\n",
    "# Calculate the length of the date range\n",
    "num_intervals = len(date_range)\n",
    "num_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Timeseries length: 11289\n",
      "count    462849.000000\n",
      "mean          0.074378\n",
      "std           0.299946\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           7.000000\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Out rides\n",
    "out_timeseries = out_df.groupby([pd.Grouper(freq=str(timestep)+'T', key='time'), 'station_id'])\n",
    "out_timeseries = out_timeseries['ride_id'].count().unstack('station_id', fill_value=0)\n",
    "\n",
    "# Convert all column names to strings, then sort\n",
    "out_timeseries.columns = out_timeseries.columns.map(str)\n",
    "out_timeseries = out_timeseries.reindex(sorted(out_timeseries.columns), axis=1)\n",
    "print('Out Timeseries length:', len(out_timeseries))\n",
    "print(print(pd.Series(out_timeseries.values.ravel()).describe()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>station_id</th>\n",
       "      <th>JC002</th>\n",
       "      <th>JC006</th>\n",
       "      <th>JC008</th>\n",
       "      <th>JC009</th>\n",
       "      <th>JC013</th>\n",
       "      <th>JC014</th>\n",
       "      <th>JC018</th>\n",
       "      <th>JC019</th>\n",
       "      <th>JC020</th>\n",
       "      <th>JC022</th>\n",
       "      <th>...</th>\n",
       "      <th>JC081</th>\n",
       "      <th>JC082</th>\n",
       "      <th>JC093</th>\n",
       "      <th>JC094</th>\n",
       "      <th>JC098</th>\n",
       "      <th>JC099</th>\n",
       "      <th>JC102</th>\n",
       "      <th>JC103</th>\n",
       "      <th>JC104</th>\n",
       "      <th>JC105</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-28 22:05:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28 22:15:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28 22:20:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28 22:35:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28 22:45:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "station_id           JC002  JC006  JC008  JC009  JC013  JC014  JC018  JC019  \\\n",
       "time                                                                          \n",
       "2023-04-28 22:05:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-28 22:15:00      0      0      0      0      0      1      0      0   \n",
       "2023-04-28 22:20:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-28 22:35:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-28 22:45:00      0      0      0      0      0      0      1      0   \n",
       "\n",
       "station_id           JC020  JC022  ...  JC081  JC082  JC093  JC094  JC098  \\\n",
       "time                               ...                                      \n",
       "2023-04-28 22:05:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-28 22:15:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-28 22:20:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-28 22:35:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-28 22:45:00      0      0  ...      0      0      0      0      0   \n",
       "\n",
       "station_id           JC099  JC102  JC103  JC104  JC105  \n",
       "time                                                    \n",
       "2023-04-28 22:05:00      0      0      0      0      0  \n",
       "2023-04-28 22:15:00      0      0      1      0      0  \n",
       "2023-04-28 22:20:00      0      0      0      0      0  \n",
       "2023-04-28 22:35:00      0      0      0      0      0  \n",
       "2023-04-28 22:45:00      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_timeseries.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In Timeseries: 18025\n",
      "count    739025.000000\n",
      "mean          0.078614\n",
      "std           0.308873\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           9.000000\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#In rides\n",
    "in_timeseries = in_df.groupby([pd.Grouper(freq=str(timestep)+'T', key='time'), 'station_id'])\n",
    "in_timeseries = in_timeseries['ride_id'].count().unstack('station_id', fill_value=0)\n",
    "in_timeseries.columns = in_timeseries.columns.map(str)\n",
    "in_timeseries = in_timeseries.reindex(sorted(in_timeseries.columns), axis=1)\n",
    "print('\\nIn Timeseries:', len(in_timeseries))\n",
    "print(print(pd.Series(in_timeseries.values.ravel()).describe()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>station_id</th>\n",
       "      <th>JC002</th>\n",
       "      <th>JC006</th>\n",
       "      <th>JC008</th>\n",
       "      <th>JC009</th>\n",
       "      <th>JC013</th>\n",
       "      <th>JC014</th>\n",
       "      <th>JC018</th>\n",
       "      <th>JC019</th>\n",
       "      <th>JC020</th>\n",
       "      <th>JC022</th>\n",
       "      <th>...</th>\n",
       "      <th>JC081</th>\n",
       "      <th>JC082</th>\n",
       "      <th>JC093</th>\n",
       "      <th>JC094</th>\n",
       "      <th>JC098</th>\n",
       "      <th>JC099</th>\n",
       "      <th>JC102</th>\n",
       "      <th>JC103</th>\n",
       "      <th>JC104</th>\n",
       "      <th>JC105</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-31 23:05:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31 23:10:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31 23:15:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31 23:20:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31 23:25:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "station_id           JC002  JC006  JC008  JC009  JC013  JC014  JC018  JC019  \\\n",
       "time                                                                          \n",
       "2023-05-31 23:05:00      0      0      0      1      0      0      0      0   \n",
       "2023-05-31 23:10:00      0      0      0      0      0      0      0      0   \n",
       "2023-05-31 23:15:00      0      0      0      0      0      0      0      1   \n",
       "2023-05-31 23:20:00      0      0      1      0      0      0      0      0   \n",
       "2023-05-31 23:25:00      0      0      0      0      0      0      0      0   \n",
       "\n",
       "station_id           JC020  JC022  ...  JC081  JC082  JC093  JC094  JC098  \\\n",
       "time                               ...                                      \n",
       "2023-05-31 23:05:00      0      0  ...      0      0      0      0      0   \n",
       "2023-05-31 23:10:00      0      0  ...      0      0      0      0      0   \n",
       "2023-05-31 23:15:00      0      0  ...      0      0      0      0      0   \n",
       "2023-05-31 23:20:00      0      0  ...      0      0      0      0      0   \n",
       "2023-05-31 23:25:00      0      0  ...      0      0      0      0      0   \n",
       "\n",
       "station_id           JC099  JC102  JC103  JC104  JC105  \n",
       "time                                                    \n",
       "2023-05-31 23:05:00      0      0      0      0      0  \n",
       "2023-05-31 23:10:00      0      0      0      0      0  \n",
       "2023-05-31 23:15:00      0      0      0      0      0  \n",
       "2023-05-31 23:20:00      0      0      0      0      0  \n",
       "2023-05-31 23:25:00      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_timeseries.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Timeseries range: 2023-03-01 00:43:53 to 2023-05-31 23:19:50\n",
      "In Timeseries range: 2023-03-01 00:48:33 to 2023-05-31 23:29:28\n"
     ]
    }
   ],
   "source": [
    "min_out_time = out_df['time'].min()\n",
    "max_out_time = out_df['time'].max()\n",
    "min_in_time = in_df['time'].min()\n",
    "max_in_time = in_df['time'].max()\n",
    "\n",
    "print(\"Out Timeseries range:\", min_out_time, \"to\", max_out_time)\n",
    "print(\"In Timeseries range:\", min_in_time, \"to\", max_in_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Timeseries range: 2023-03-01 00:48:33 to 2023-05-31 23:19:50\n",
      "In Timeseries range: 2023-03-01 00:48:33 to 2023-05-31 23:19:50\n"
     ]
    }
   ],
   "source": [
    "# Assuming min_out_time, max_out_time, min_in_time, and max_in_time are already defined\n",
    "# Find the latest start time\n",
    "common_start_time = max(min_out_time, min_in_time)\n",
    "\n",
    "# Find the earliest end time\n",
    "common_end_time = min(max_out_time, max_in_time)\n",
    "\n",
    "# Now filter both dataframes to only include rows within the common time range\n",
    "out_df_common = out_df[(out_df['time'] >= common_start_time) & (out_df['time'] <= common_end_time)]\n",
    "in_df_common = in_df[(in_df['time'] >= common_start_time) & (in_df['time'] <= common_end_time)]\n",
    "\n",
    "# You can then re-create the timeseries for each dataframe\n",
    "out_timeseries_common = out_df_common.groupby([pd.Grouper(freq=str(timestep)+'T', key='time'), 'station_id']).count().unstack('station_id', fill_value=0)\n",
    "out_timeseries_common.columns = out_timeseries_common.columns.map(str)\n",
    "out_timeseries_common = out_timeseries_common.reindex(sorted(out_timeseries_common.columns), axis=1)\n",
    "\n",
    "in_timeseries_common = in_df_common.groupby([pd.Grouper(freq=str(timestep)+'T', key='time'), 'station_id']).count().unstack('station_id', fill_value=0)\n",
    "in_timeseries_common.columns = in_timeseries_common.columns.map(str)\n",
    "in_timeseries_common = in_timeseries_common.reindex(sorted(in_timeseries_common.columns), axis=1)\n",
    "\n",
    "# After this step, out_timeseries_common and in_timeseries_common should have the same time range\n",
    "print('Out Timeseries range:', common_start_time, \"to\", common_end_time)\n",
    "print('In Timeseries range:', common_start_time, \"to\", common_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the column names to be the part after the comma and remove the leading '(' and trailing ')'\n",
    "out_timeseries_common.columns = [col.split(',')[1][:-1].strip(\" '\") for col in out_timeseries_common.columns]\n",
    "in_timeseries_common.columns = [col.split(',')[1][:-1].strip(\" '\") for col in in_timeseries_common.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17923, 41)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_timeseries_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18023, 41)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_timeseries_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned Out Timeseries length: 20642\n",
      "Aligned In Timeseries length: 20642\n"
     ]
    }
   ],
   "source": [
    "# Create a new time index that includes every time point from both DataFrames\n",
    "common_time_index = out_timeseries_common.index.union(in_timeseries_common.index)\n",
    "\n",
    "# Reindex both DataFrames to this new time index\n",
    "out_timeseries_aligned = out_timeseries_common.reindex(common_time_index, fill_value=0)\n",
    "in_timeseries_aligned = in_timeseries_common.reindex(common_time_index, fill_value=0)\n",
    "\n",
    "# Now both out_timeseries_aligned and in_timeseries_aligned should have the same length\n",
    "print('Aligned Out Timeseries length:', len(out_timeseries_aligned))\n",
    "print('Aligned In Timeseries length:', len(in_timeseries_aligned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Aligned Out Timeseries length: 16992\n",
      "New Aligned In Timeseries length: 16992\n"
     ]
    }
   ],
   "source": [
    "start_time = common_time_index.min()\n",
    "\n",
    "# Calculate the end time by adding (16992 - 1) * 5 minutes to the start time\n",
    "end_time = start_time + pd.Timedelta(minutes=5 * (16992 - 1))\n",
    "\n",
    "# Create a date range with exactly 16992 samples, each 5 minutes apart\n",
    "new_time_index = pd.date_range(start=start_time, end=end_time, freq='5T')\n",
    "\n",
    "# Reindex both DataFrames to this new time index, filling missing data with zeros\n",
    "out_timeseries_aligned = out_timeseries_common.reindex(new_time_index, fill_value=0)\n",
    "in_timeseries_aligned = in_timeseries_common.reindex(new_time_index, fill_value=0)\n",
    "\n",
    "# Check the results\n",
    "print('New Aligned Out Timeseries length:', len(out_timeseries_aligned))\n",
    "print('New Aligned In Timeseries length:', len(in_timeseries_aligned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JC002</th>\n",
       "      <th>JC006</th>\n",
       "      <th>JC008</th>\n",
       "      <th>JC009</th>\n",
       "      <th>JC013</th>\n",
       "      <th>JC014</th>\n",
       "      <th>JC018</th>\n",
       "      <th>JC019</th>\n",
       "      <th>JC020</th>\n",
       "      <th>JC022</th>\n",
       "      <th>...</th>\n",
       "      <th>JC081</th>\n",
       "      <th>JC082</th>\n",
       "      <th>JC093</th>\n",
       "      <th>JC094</th>\n",
       "      <th>JC098</th>\n",
       "      <th>JC099</th>\n",
       "      <th>JC102</th>\n",
       "      <th>JC103</th>\n",
       "      <th>JC104</th>\n",
       "      <th>JC105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:20:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:25:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:35:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:40:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     JC002  JC006  JC008  JC009  JC013  JC014  JC018  JC019  \\\n",
       "2023-04-29 00:20:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-29 00:25:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-29 00:30:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-29 00:35:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-29 00:40:00      0      0      0      0      0      0      0      0   \n",
       "\n",
       "                     JC020  JC022  ...  JC081  JC082  JC093  JC094  JC098  \\\n",
       "2023-04-29 00:20:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-29 00:25:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-29 00:30:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-29 00:35:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-29 00:40:00      0      0  ...      0      0      0      0      0   \n",
       "\n",
       "                     JC099  JC102  JC103  JC104  JC105  \n",
       "2023-04-29 00:20:00      0      0      0      1      0  \n",
       "2023-04-29 00:25:00      0      0      0      0      0  \n",
       "2023-04-29 00:30:00      0      0      0      0      0  \n",
       "2023-04-29 00:35:00      0      0      0      0      0  \n",
       "2023-04-29 00:40:00      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_timeseries_aligned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JC002</th>\n",
       "      <th>JC006</th>\n",
       "      <th>JC008</th>\n",
       "      <th>JC009</th>\n",
       "      <th>JC013</th>\n",
       "      <th>JC014</th>\n",
       "      <th>JC018</th>\n",
       "      <th>JC019</th>\n",
       "      <th>JC020</th>\n",
       "      <th>JC022</th>\n",
       "      <th>...</th>\n",
       "      <th>JC081</th>\n",
       "      <th>JC082</th>\n",
       "      <th>JC093</th>\n",
       "      <th>JC094</th>\n",
       "      <th>JC098</th>\n",
       "      <th>JC099</th>\n",
       "      <th>JC102</th>\n",
       "      <th>JC103</th>\n",
       "      <th>JC104</th>\n",
       "      <th>JC105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:20:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:25:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:35:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-29 00:40:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     JC002  JC006  JC008  JC009  JC013  JC014  JC018  JC019  \\\n",
       "2023-04-29 00:20:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-29 00:25:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-29 00:30:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-29 00:35:00      0      0      0      0      0      0      0      0   \n",
       "2023-04-29 00:40:00      0      0      0      0      0      0      0      0   \n",
       "\n",
       "                     JC020  JC022  ...  JC081  JC082  JC093  JC094  JC098  \\\n",
       "2023-04-29 00:20:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-29 00:25:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-29 00:30:00      0      0  ...      0      0      0      0      0   \n",
       "2023-04-29 00:35:00      1      0  ...      0      0      0      0      0   \n",
       "2023-04-29 00:40:00      0      0  ...      0      0      0      0      0   \n",
       "\n",
       "                     JC099  JC102  JC103  JC104  JC105  \n",
       "2023-04-29 00:20:00      0      0      0      0      0  \n",
       "2023-04-29 00:25:00      0      0      0      0      0  \n",
       "2023-04-29 00:30:00      0      0      0      0      0  \n",
       "2023-04-29 00:35:00      0      0      0      0      0  \n",
       "2023-04-29 00:40:00      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_timeseries_aligned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['JC002', 'JC006', 'JC008', 'JC009', 'JC013', 'JC014', 'JC018', 'JC019',\n",
       "       'JC020', 'JC022', 'JC023', 'JC024', 'JC027', 'JC032', 'JC038', 'JC051',\n",
       "       'JC052', 'JC053', 'JC055', 'JC057', 'JC059', 'JC063', 'JC065', 'JC066',\n",
       "       'JC072', 'JC074', 'JC075', 'JC076', 'JC077', 'JC078', 'JC080', 'JC081',\n",
       "       'JC082', 'JC093', 'JC094', 'JC098', 'JC099', 'JC102', 'JC103', 'JC104',\n",
       "       'JC105'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_timeseries_aligned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = out_timeseries_aligned.values\n",
    "feature2 = in_timeseries_aligned.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16992, 41, 2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack the features to create a new array of shape (11964, 42, 2)\n",
    "data = np.stack((feature1, feature2), axis=-1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(r'C:\\Users\\srush\\bike share model\\cleaned&merged_data\\your_data.npz', feature_data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can access the second feature for all points\n",
    "second_feature_data = data[:, :, 1]\n",
    "\n",
    "# Let's print the shape of the resulting slice\n",
    "second_feature_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 42 nodes, each node (station) has 2 features - number of bikes leaving the station and number of bikes entering the station. each data is collected every 30 mins interval. \n",
    "\n",
    "The idea is to sample from the past segments of the data that are predictors for the future segment.\n",
    "\n",
    "If we want to predict the bike counts in the next hour e.g. (Thursday 8:00 AM) \n",
    "\n",
    "We can use :\n",
    "### 1. The recent segment\n",
    "\n",
    "We use the last two hours. Based on the traffic from 6:00 to 8:00 AM, we will predict the traffic of 8:00 AM\n",
    "\n",
    "Intuition : The formation and dispersion of traffic congestions are gradual. So, the just past traffic flows inevitably have influence on the future traffic flows\n",
    "\n",
    "### 2. The daily-periodic segment\n",
    "\n",
    "We use the same hour in the last week and the same hour yesterday and the day before. Based on the traffic at 8:00 AM on tuesday and wednesday, we will predict the traffic of 8:00 AM on thursday.\n",
    "\n",
    "Intuition: Due to the regular daily routine of people, traffic data may show repeated patterns, such as the daily morning peaks. The purpose of the daily-period component is to model the daily periodicity of traffic data.\n",
    "\n",
    "### 3. The weekly-periodic segment\n",
    "\n",
    "We use the same hour in the last week and the same hour in the week before the last week. Based on the traffic at 8:00 AM on the thursday in the past two weeks, we will predict the traffic of 8:00 AM\n",
    "\n",
    "Intuition: Usually, the traffic patterns on Monday have a certain similarity with the traffic patterns on Mondays in history, but may be greatly different from those on weekends. Thus, the weekly-period component is designed to capture the weekly periodic features in traffic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_data(sequence_length, num_of_depend, label_start_idx,num_for_predict, units, points_per_hour):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence_length: int, length of all history data\n",
    "    num_of_depend: int,\n",
    "    label_start_idx: int, the first index of predicting target\n",
    "    num_for_predict: int, the number of points will be predicted for each sample\n",
    "    units: int, week: 7 * 24, day: 24, recent(hour): 1\n",
    "    points_per_hour: int, number of points per hour, depends on data\n",
    "    Returns\n",
    "    ----------\n",
    "    list[(start_idx, end_idx)]\n",
    "    '''\n",
    "\n",
    "    if points_per_hour < 0:\n",
    "        raise ValueError(\"points_per_hour should be greater than 0!\")\n",
    "\n",
    "    if label_start_idx + num_for_predict > sequence_length:\n",
    "        return None\n",
    "\n",
    "    x_idx = []\n",
    "    for i in range(1, num_of_depend + 1):\n",
    "        start_idx = label_start_idx - points_per_hour * units * i\n",
    "        end_idx = start_idx + num_for_predict\n",
    "        if start_idx >= 0:\n",
    "            x_idx.append((start_idx, end_idx))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    if len(x_idx) != num_of_depend:\n",
    "        return None\n",
    "\n",
    "    return x_idx[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_indices(data_sequence, num_of_weeks, num_of_days, num_of_hours, label_start_idx, num_for_predict, points_per_hour=12):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_sequence: np.ndarray shape is (sequence_length, num_of_vertices, num_of_features)\n",
    "    num_of_weeks, num_of_days, num_of_hours: int\n",
    "    label_start_idx: int, the first index of predicting target\n",
    "    num_for_predict: int,the number of points will be predicted for each sample\n",
    "    points_per_hour: int, default 12, number of points per hour\n",
    "    Returns\n",
    "    ----------\n",
    "    week_sample: np.ndarray shape is (num_of_weeks * points_per_hour, num_of_vertices, num_of_features)\n",
    "    day_sample: np.ndarray shape is (num_of_days * points_per_hour,  num_of_vertices, num_of_features)\n",
    "    hour_sample: np.ndarray   shape is (num_of_hours * points_per_hour, num_of_vertices, num_of_features)\n",
    "    target: np.ndarray shape is (num_for_predict, num_of_vertices, num_of_features)\n",
    "    '''\n",
    "    week_sample, day_sample, hour_sample = None, None, None\n",
    "#------------------------------------Ignore\n",
    "    if label_start_idx + num_for_predict > data_sequence.shape[0]: \n",
    "        return week_sample, day_sample, hour_sample, None\n",
    "\n",
    "    if num_of_weeks > 0:\n",
    "        week_indices = search_data(data_sequence.shape[0], num_of_weeks, label_start_idx, num_for_predict,7 * 24, points_per_hour)\n",
    "        if not week_indices:\n",
    "            return None, None, None, None\n",
    "\n",
    "        week_sample = np.concatenate([data_sequence[i: j] for i, j in week_indices], axis=0)\n",
    "\n",
    "    if num_of_days > 0:\n",
    "        day_indices = search_data(data_sequence.shape[0], num_of_days,  label_start_idx, num_for_predict, 24, points_per_hour)\n",
    "        if not day_indices:\n",
    "            return None, None, None, None\n",
    "\n",
    "        day_sample = np.concatenate([data_sequence[i: j] for i, j in day_indices], axis=0)\n",
    "#----------------------------------Continue\n",
    "    if num_of_hours > 0:\n",
    "        hour_indices = search_data(data_sequence.shape[0], num_of_hours, label_start_idx, num_for_predict, 1, points_per_hour)\n",
    "        if not hour_indices:\n",
    "            return None, None, None, None\n",
    "        hour_sample = np.concatenate([data_sequence[i: j] for i, j in hour_indices], axis=0)\n",
    "    \n",
    "    if num_of_hours > 10:\n",
    "        return 1;\n",
    "    target = data_sequence[label_start_idx: label_start_idx + num_for_predict]\n",
    "\n",
    "    return week_sample, day_sample, hour_sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_generate_dataset(graph_signal_matrix_filename, num_of_weeks, num_of_days, num_of_hours, num_for_predict, points_per_hour=12):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph_signal_matrix_filename: str, path of graph signal matrix file\n",
    "    num_of_weeks, num_of_days, num_of_hours: int\n",
    "    num_for_predict: int\n",
    "    points_per_hour: int, default 12, depends on data\n",
    "    Returns\n",
    "    ----------\n",
    "    feature: np.ndarray, shape is (num_of_samples, num_of_depend * points_per_hour, num_of_vertices, num_of_features)\n",
    "    target: np.ndarray, shape is (num_of_samples, num_of_vertices, num_for_predict)\n",
    "    '''\n",
    "    #--------------------------------- Read original data \n",
    "    data_seq = np.load(graph_signal_matrix_filename)['feature_data']  # (sequence_length, num_of_vertices, num_of_features) (16992, 307, 3)\n",
    "    \n",
    "    #---------------------------------\n",
    "    all_samples = []\n",
    "    for idx in range(data_seq.shape[0]):\n",
    "        sample = get_sample_indices(data_seq, num_of_weeks, num_of_days, num_of_hours, idx, num_for_predict, points_per_hour)\n",
    "        if ((sample[0] is None) and (sample[1] is None) and (sample[2] is None)):\n",
    "            continue\n",
    "\n",
    "        week_sample, day_sample, hour_sample, target = sample #  week_sample, day_sample are None because we are predicting per hour\n",
    "        #print(target.shape) # hour_sample and target (12, 307, 3)\n",
    "        sample = []  # [(week_sample),(day_sample),(hour_sample),target,time_sample]\n",
    "\n",
    "#-------------------------------- Ignore\n",
    "        if num_of_weeks > 0:\n",
    "            week_sample = np.expand_dims(week_sample, axis=0).transpose((0, 2, 3, 1))  # (1,N,F,T)\n",
    "            sample.append(week_sample)\n",
    "\n",
    "        if num_of_days > 0:\n",
    "            day_sample = np.expand_dims(day_sample, axis=0).transpose((0, 2, 3, 1))  # (1,N,F,T)\n",
    "            sample.append(day_sample)\n",
    "#----------------------------------Continue\n",
    "        if num_of_hours > 0:\n",
    "            hour_sample = np.expand_dims(hour_sample, axis=0).transpose((0, 2, 3, 1))  # (1,N,F,T)\n",
    "            sample.append(hour_sample)\n",
    "\n",
    "        target = np.expand_dims(target, axis=0).transpose((0, 2, 3, 1))[:, :, 0, :]  # (1,N,T)\n",
    "        sample.append(target)\n",
    "        time_sample = np.expand_dims(np.array([idx]), axis=0)  # (1,1)\n",
    "        sample.append(time_sample)\n",
    "        all_samples.append(sample)#sampe：[(week_sample),(day_sample),(hour_sample),target,time_sample] = [(1,N,F,Tw),(1,N,F,Td),(1,N,F,Th),(1,N,Tpre),(1,1)]\n",
    "    \n",
    "    split_line1 = int(len(all_samples) * 0.6)\n",
    "    split_line2 = int(len(all_samples) * 0.8)\n",
    "\n",
    "    training_set = [np.concatenate(i, axis=0)  for i in zip(*all_samples[:split_line1])] #[(B,N,F,Tw),(B,N,F,Td),(B,N,F,Th),(B,N,Tpre),(B,1)]\n",
    "    validation_set = [np.concatenate(i, axis=0) for i in zip(*all_samples[split_line1: split_line2])]\n",
    "    testing_set = [np.concatenate(i, axis=0) for i in zip(*all_samples[split_line2:])]\n",
    "\n",
    "    return training_set, validation_set, testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_data']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "graph_signal_matrix_filename = r'C:\\\\Users\\\\srush\\\\bike share model\\\\cleaned&merged_data\\\\your_data.npz'\n",
    "data = np.load(graph_signal_matrix_filename)\n",
    "\n",
    "# Print all items in the file\n",
    "print(list(data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16992, 41, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_signal_matrix_filename = r'C:\\Users\\srush\\bike share model\\cleaned&merged_data\\your_data.npz'\n",
    "data = np.load(graph_signal_matrix_filename)\n",
    "data['feature_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(graph_signal_matrix_filename)\n",
    "data['feature_data'].shape\n",
    "num_of_vertices = 41\n",
    "points_per_hour = 12\n",
    "num_for_predict = 12\n",
    "num_of_weeks = 0\n",
    "num_of_days = 0\n",
    "num_of_hours = 1\n",
    "\n",
    "training_set, validation_set, testing_set = read_and_generate_dataset(graph_signal_matrix_filename, 0, 0, num_of_hours, \n",
    "                                                                      num_for_predict, points_per_hour=points_per_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train, val, test):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    train, val, test: np.ndarray (B,N,F,T)\n",
    "    Returns\n",
    "    ----------\n",
    "    stats: dict, two keys: mean and std\n",
    "    train_norm, val_norm, test_norm: np.ndarray,\n",
    "                                     shape is the same as original\n",
    "    '''\n",
    "\n",
    "    assert train.shape[1:] == val.shape[1:] and val.shape[1:] == test.shape[1:]  # ensure the num of nodes is the same\n",
    "    mean = train.mean(axis=(0,1,3), keepdims=True)\n",
    "    std = train.std(axis=(0,1,3), keepdims=True)\n",
    "    print('mean.shape:',mean.shape)\n",
    "    print('std.shape:',std.shape)\n",
    "\n",
    "    def normalize(x):\n",
    "        return (x - mean) / std\n",
    "\n",
    "    train_norm = normalize(train)\n",
    "    val_norm = normalize(val)\n",
    "    test_norm = normalize(test)\n",
    "\n",
    "    return {'_mean': mean, '_std': std}, train_norm, val_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean.shape: (1, 1, 2, 1)\n",
      "std.shape: (1, 1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.concatenate(training_set[:-2], axis=-1)  # (B,N,F,T')\n",
    "val_x = np.concatenate(validation_set[:-2], axis=-1)\n",
    "test_x = np.concatenate(testing_set[:-2], axis=-1)\n",
    "\n",
    "train_target = training_set[-2]  # (B,N,T)\n",
    "val_target = validation_set[-2]\n",
    "test_target = testing_set[-2]\n",
    "\n",
    "train_timestamp = training_set[-1]  # (B,1)\n",
    "val_timestamp = validation_set[-1]\n",
    "test_timestamp = testing_set[-1]\n",
    "\n",
    "(stats, train_x_norm, val_x_norm, test_x_norm) = normalization(train_x, val_x, test_x)\n",
    "\n",
    "all_data = {'train': { 'x': train_x_norm, 'target': train_target,'timestamp': train_timestamp},\n",
    "            'val': {'x': val_x_norm, 'target': val_target, 'timestamp': val_timestamp},\n",
    "            'test': {'x': test_x_norm, 'target': test_target, 'timestamp': test_timestamp},\n",
    "            'stats': {'_mean': stats['_mean'], '_std': stats['_std']} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x: (10181, 41, 2, 12)\n",
      "train target: (10181, 41, 12)\n",
      "train timestamp: (10181, 1)\n",
      "\n",
      "val x: (3394, 41, 2, 12)\n",
      "val target: (3394, 41, 12)\n",
      "val timestamp: (3394, 1)\n",
      "\n",
      "test x: (3394, 41, 2, 12)\n",
      "test target: (3394, 41, 12)\n",
      "test timestamp: (3394, 1)\n",
      "\n",
      "train data _mean : (1, 1, 2, 1) [[[[0.0423665 ]\n",
      "   [0.04235911]]]]\n",
      "train data _std : (1, 1, 2, 1) [[[[0.22637724]\n",
      "   [0.22426236]]]]\n"
     ]
    }
   ],
   "source": [
    "print('train x:', all_data['train']['x'].shape)\n",
    "print('train target:', all_data['train']['target'].shape)\n",
    "print('train timestamp:', all_data['train']['timestamp'].shape)\n",
    "print()\n",
    "print('val x:', all_data['val']['x'].shape)\n",
    "print('val target:', all_data['val']['target'].shape)\n",
    "print('val timestamp:', all_data['val']['timestamp'].shape)\n",
    "print()\n",
    "print('test x:', all_data['test']['x'].shape)\n",
    "print('test target:', all_data['test']['target'].shape)\n",
    "print('test timestamp:', all_data['test']['timestamp'].shape)\n",
    "print()\n",
    "print('train data _mean :', all_data['stats']['_mean'].shape, all_data['stats']['_mean'])\n",
    "print('train data _std :', all_data['stats']['_std'].shape, all_data['stats']['_std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file: .\\your_data_r1_d0_w0_astcgn\n"
     ]
    }
   ],
   "source": [
    "file = os.path.basename(graph_signal_matrix_filename).split('.')[0]\n",
    "dirpath = '.'\n",
    "filename = os.path.join(dirpath, file + '_r' + str(num_of_hours) + '_d' + str(num_of_days) + '_w' + str(num_of_weeks)) + '_astcgn'\n",
    "print('save file:', filename)\n",
    "np.savez_compressed(filename,\n",
    "                train_x=all_data['train']['x'],train_target=all_data['train']['target'],train_timestamp=all_data['train']['timestamp'],\n",
    "                val_x=all_data['val']['x'], val_target=all_data['val']['target'],val_timestamp=all_data['val']['timestamp'],\n",
    "                test_x=all_data['test']['x'], test_target=all_data['test']['target'], test_timestamp=all_data['test']['timestamp'],\n",
    "                mean=all_data['stats']['_mean'], std=all_data['stats']['_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnncuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
